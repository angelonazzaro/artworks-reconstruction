{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27eca293e0492052",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5123b96350f60dd1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-22T18:08:59.145414Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pygments.formatters import img\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.metrics import structural_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from preprocessing.edge_extraction import *\n",
    "from feature_extraction import * \n",
    "from preprocessing.fourier_transform import * \n",
    "from preprocessing.image_conversion import * \n",
    "from clustering import *\n",
    "from preprocessing.contrast_enhancement import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cbd2812370b24e",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "To reduce noise in images of whole artworks and fragments, we initially considered using the Fourier transform to process the images in the frequency domain.\n",
    "\n",
    "While converting an image from RGBA to grayscale simplifies processing, it results in the loss of RGB color and alpha channel data, which can be problematic if that information is needed later. Therefore, we chose to split the image into its primary color channels (excluding the alpha channel) and process each channel separately in the frequency domain. After filtering, we planned to reconstruct the filtered image by recombining the processed channels.\n",
    "\n",
    "However, after several trials, we found that processing the channels separately led to significant information loss in one or more channels. Consequently, we decided to use the NLMeansDenoising filter instead.\n",
    "\n",
    "Since our goal is to cluster fragments that belong to the same image, we focus on maintaining \"continuity\" along the fragment borders. Therefore, our process emphasizes the information present along these edges.\n",
    "\n",
    "Steps:\n",
    "1. Extract a working region from the borders of the fragment.\n",
    "2. Filter out the transparent pixels from the working region.\n",
    "3. Denoise the working region.\n",
    "\n",
    "**CONSIDERATION**: Contrast enhancement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621d1d1f73e963",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "To extract relevant features from the fragments, we employ two methods:\n",
    "- Color Histograms\n",
    "- Gradient Jacobians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f6711ab6c7ac0",
   "metadata": {},
   "source": [
    "## Color Histograms\n",
    "\n",
    "Color histograms are graphical representations of the distribution of colors in an image. They quantify the number of pixels that have specific color values, effectively capturing the color composition of the image. By analyzing the color histograms of image fragments, we can compare and cluster similar fragments based on their color distributions.\n",
    "\n",
    "**This technique is particularly useful for identifying and matching regions of images that share similar color patterns**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9685596a-f71b-4d8a-86ce-59caae08250f",
   "metadata": {},
   "source": [
    "## Similarity Structural Index Measure\n",
    "\n",
    "The Similarity Structural Index Measure (SSIM) is used as a metric to measure the similarity between two given images incorporating illuminance, contrast and structural information. \n",
    "For each reference image we compute the SSIM for each fragment on the key idea that the fragments of the same image should have the highest SSIM since they share structural, illumination \n",
    "and contrast information with the reference image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d385092b-d3ca-4956-9d28-bdb63464c178",
   "metadata": {},
   "source": [
    "We use both the color histogram and the SSIM to mainly highlight color and structural information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf3d70817395f58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Structural Similarity (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81b7269a328bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "before = cv2.imread('data/5.38.35.png')\n",
    "after = cv2.imread('references/5.37.jpg')\n",
    "\n",
    "max_w = max(before.shape[0], after.shape[0])\n",
    "max_h = max(before.shape[1], after.shape[1])\n",
    "\n",
    "before = cv2.resize(before, (max_w, max_h))\n",
    "after = cv2.resize(after, (max_w, max_h))\n",
    "\n",
    "# Convert images to grayscale\n",
    "before_gray = cv2.cvtColor(before, cv2.COLOR_BGR2GRAY)\n",
    "after_gray = cv2.cvtColor(after, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Compute SSIM between two images\n",
    "(score, diff) = structural_similarity(before_gray, after_gray, full=True)\n",
    "print(\"Image similarity\", score)\n",
    "\n",
    "# The diff image contains the actual image differences between the two images\n",
    "# and is represented as a floating point data type in the range [0,1]\n",
    "# so we must convert the array to 8-bit unsigned integers in the range\n",
    "# [0,255] before we can use it with OpenCV\n",
    "diff = (diff * 255).astype(\"uint8\")\n",
    "\n",
    "# Threshold the difference image, followed by finding contours to\n",
    "# obtain the regions of the two input images that differ\n",
    "thresh = cv2.threshold(diff, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "mask = np.zeros(before.shape, dtype='uint8')\n",
    "filled_after = after.copy()\n",
    "\n",
    "for c in contours:\n",
    "    area = cv2.contourArea(c)\n",
    "    if area > 40:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        cv2.rectangle(before, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "        cv2.rectangle(after, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "        cv2.drawContours(mask, [c], 0, (0,255,0), -1)\n",
    "        cv2.drawContours(filled_after, [c], 0, (0,255,0), -1)\n",
    "\n",
    "cv2.imshow('before', before)\n",
    "cv2.imshow('after', after)\n",
    "cv2.imshow('diff',diff)\n",
    "cv2.imshow('mask',mask)\n",
    "cv2.imshow('filled after',filled_after)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4951b3de-033a-4133-a45d-aa457b21dd50",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "We perform \"iterative clustering\" using color histograms and SSIM scores for each fragment relative to a reference image. Our goal is to create two clusters for each reference image:\n",
    "- **IN-CLUSTER**: Contains all and only the fragments of the reference image.\n",
    "- **OUT-CLUSTER**: Contains the spurious fragments.\n",
    "\n",
    "**Determining Cluster Identity**\n",
    "\n",
    "To determine which cluster is which, we use \"dummy\" precision, recall, and F1 scores, leveraging our knowledge of the reference image and the number of its fragments. Initially, we focus on the cluster with the highest recall score, identifying it as the IN-CLUSTER. This cluster has the most fragments of the reference image under examination.\n",
    "\n",
    "Next, we refine the IN-CLUSTER to reduce the number of spurious fragments, thereby increasing its precision and purity. Once refined, the fragments in the IN-CLUSTER are excluded from further clustering iterations.\n",
    "\n",
    "This process is repeated for each reference image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e1a44-3c8b-4177-b91b-49e11d1a2523",
   "metadata": {},
   "source": [
    "## Dataset Creation\n",
    "\n",
    "We compute the SSIM score on entire fragments, but consider only the color histograms of the borders for reasons of \"continuity.\" If two fragments are from the same image, they should have similar color distribution on the borders, especially if they were originally adjacent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273c48ee-86bf-458c-8d77-e7a8890a8ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5\n",
    "references_path = \"references\"\n",
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82b67d01-987c-4c15-8db9-06aeb8921b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving reference ids: 100%|██████████| 8/8 [00:00<00:00, 33354.31it/s]\n",
      "Retrieving reference images: 100%|██████████| 8/8 [00:00<00:00, 57.45it/s]\n"
     ]
    }
   ],
   "source": [
    "reference_images_ids = [reference.split(\".\")[1] for reference in tqdm(os.listdir(references_path), desc=\"Retrieving reference ids\")]\n",
    "reference_images = [cv.imread(os.path.join(references_path, reference), cv.IMREAD_UNCHANGED) for reference in tqdm(os.listdir(references_path), desc=\"Retrieving reference images\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2acf6a6d-014c-436f-9ce3-27c3bf735faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ssim_scores(fragments, reference_image, reference_id):\n",
    "    ssim_scores = []\n",
    "    \n",
    "    # compute the SSIM for each fragment with regard to a specific reference image\n",
    "    for fragment in tqdm(fragments, desc=f\"Calculating SSIM scores for reference ID {reference_id}\"):\n",
    "        max_w = max(fragment.shape[0], reference_image.shape[0])\n",
    "        max_h = max(fragment.shape[1], reference_image.shape[1])\n",
    "    \n",
    "        fragment = cv.resize(fragment, (max_w, max_h))\n",
    "        reference = cv.resize(reference_image, (max_w, max_h))\n",
    "    \n",
    "        # Convert images to grayscale\n",
    "        fragment_gray = cv.cvtColor(fragment, cv.COLOR_BGR2GRAY)\n",
    "        reference_gray = cv.cvtColor(reference, cv.COLOR_BGR2GRAY)\n",
    "        (score, diff) = structural_similarity(fragment_gray, reference_gray, full=True)\n",
    "        ssim_scores.append(score)\n",
    "    \n",
    "    return ssim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c9e4530-eed1-409c-8b3f-1a7d70176298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_IN_clusters(reference_id, threshold, output_dir, metric):\n",
    "    scores = compute_metrics(reference_id, output_dir, metric=metric)\n",
    "    print(scores)\n",
    "    opt_clusters = {}\n",
    "    # select the IN-CLUSTER\n",
    "    # this is the generalized form in case we want to consider more than 2 clusters of more than one reference image per time\n",
    "    for max_item in scores[f\"max_{metric}\"]:\n",
    "        if max_item[1] >= threshold:\n",
    "            if reference_id in opt_clusters:\n",
    "                opt_clusters[reference_id].append(max_item[0])\n",
    "            else:\n",
    "                opt_clusters[reference_id] = [max_item[0]]\n",
    "                    \n",
    "    return opt_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59a8bc03-cbb8-4ad9-9c12-8296ec7d8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_data_dir = \"./optimal_data\"\n",
    "metric = \"recall\"\n",
    "metric_threshold = 0.80\n",
    "output_dir = \"clusters/kmeans/colors_ssim\"\n",
    "optimal_dir = \"optimal_clusters/kmeans/colors_ssim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97187123d06ba40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 out of 8 - Reference ID 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dataset: 100%|██████████| 328/328 [00:03<00:00, 101.21it/s]\n",
      "Creating dataset: 100%|██████████| 328/328 [00:13<00:00, 23.71it/s]\n",
      "Calculating SSIM scores for reference ID 33: 100%|██████████| 328/328 [00:02<00:00, 113.76it/s]\n",
      "Computing color histograms: 100%|██████████| 328/328 [00:00<00:00, 106736.89it/s]\n",
      "Creating cluster dirs: 100%|██████████| 328/328 [00:00<00:00, 2897.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_recall': [('cluster_0', 0.9555555555555556)], 'scores': {'cluster_1': {'precision': 0.010416666666666666, 'recall': 0.044444444444444446, 'f1': 0.01687763713080169}, 'cluster_0': {'precision': 0.3161764705882353, 'recall': 0.9555555555555556, 'f1': 0.47513812154696133}}}\n",
      "{'33': ['cluster_0']}\n",
      "Iteration 2 out of 8 - Reference ID 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dataset: 100%|██████████| 192/192 [00:01<00:00, 115.92it/s]\n",
      "Creating dataset: 100%|██████████| 192/192 [00:05<00:00, 37.90it/s]\n",
      "Calculating SSIM scores for reference ID 36:  11%|█▏        | 22/192 [00:09<01:16,  2.22it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m working_region_fragments_dataset \u001b[38;5;241m=\u001b[39m create_dataset(img_dir\u001b[38;5;241m=\u001b[39mdata_dir, threshold\u001b[38;5;241m=\u001b[39mthreshold)\n\u001b[1;32m     16\u001b[0m original_fragments_dataset \u001b[38;5;241m=\u001b[39m create_dataset(img_dir\u001b[38;5;241m=\u001b[39mdata_dir, extract_borders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 18\u001b[0m ssim_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_ssim_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_fragments_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m color_histograms \u001b[38;5;241m=\u001b[39m compute_color_histograms(working_region_fragments_dataset)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# actual dataset\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 15\u001b[0m, in \u001b[0;36mcompute_ssim_scores\u001b[0;34m(fragments, reference_image, reference_id)\u001b[0m\n\u001b[1;32m     13\u001b[0m     fragment_gray \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mcvtColor(fragment, cv\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     14\u001b[0m     reference_gray \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mcvtColor(reference, cv\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m---> 15\u001b[0m     (score, diff) \u001b[38;5;241m=\u001b[39m \u001b[43mstructural_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfragment_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     ssim_scores\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssim_scores\n",
      "File \u001b[0;32m~/PyCharmProjects/artworks-reconstruction/.venv/lib/python3.10/site-packages/skimage/metrics/_structural_similarity.py:248\u001b[0m, in \u001b[0;36mstructural_similarity\u001b[0;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# compute (weighted) means\u001b[39;00m\n\u001b[1;32m    247\u001b[0m ux \u001b[38;5;241m=\u001b[39m filter_func(im1, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfilter_args)\n\u001b[0;32m--> 248\u001b[0m uy \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfilter_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# compute (weighted) variances and covariances\u001b[39;00m\n\u001b[1;32m    251\u001b[0m uxx \u001b[38;5;241m=\u001b[39m filter_func(im1 \u001b[38;5;241m*\u001b[39m im1, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfilter_args)\n",
      "File \u001b[0;32m~/PyCharmProjects/artworks-reconstruction/.venv/lib/python3.10/site-packages/scipy/ndimage/_filters.py:1092\u001b[0m, in \u001b[0;36muniform_filter\u001b[0;34m(input, size, output, mode, cval, origin, axes)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1091\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, size, origin, mode \u001b[38;5;129;01min\u001b[39;00m axes:\n\u001b[0;32m-> 1092\u001b[0m         \u001b[43muniform_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1094\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/PyCharmProjects/artworks-reconstruction/.venv/lib/python3.10/site-packages/scipy/ndimage/_filters.py:1020\u001b[0m, in \u001b[0;36muniform_filter1d\u001b[0;34m(input, size, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m   1018\u001b[0m mode \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m complex_output:\n\u001b[0;32m-> 1020\u001b[0m     \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m                               \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     _nd_image\u001b[38;5;241m.\u001b[39muniform_filter1d(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mreal, size, axis, output\u001b[38;5;241m.\u001b[39mreal, mode,\n\u001b[1;32m   1024\u001b[0m                                numpy\u001b[38;5;241m.\u001b[39mreal(cval), origin)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(optimal_data_dir, exist_ok=True)\n",
    "n_references = len(reference_images_ids)\n",
    "c = 0\n",
    "\n",
    "for i in range(len(reference_images_ids)):\n",
    "    reference_id = reference_images_ids[i]\n",
    "    reference_image = reference_images[i]\n",
    "\n",
    "    print(f\"Iteration {i + 1} out of {n_references} - Reference ID {reference_id}\")\n",
    "    \n",
    "    working_region_fragments_dataset = create_dataset(img_dir=data_dir, threshold=threshold)\n",
    "    original_fragments_dataset = create_dataset(img_dir=data_dir, extract_borders=False)\n",
    "\n",
    "    ssim_scores = compute_ssim_scores(original_fragments_dataset, reference_image, reference_id)\n",
    "    color_histograms = compute_color_histograms(working_region_fragments_dataset)\n",
    "    # actual dataset\n",
    "    X = []\n",
    "    for idx, color_histogram in enumerate(color_histograms):\n",
    "        combined_features = np.concatenate((color_histogram, [ssim_scores[idx]]))\n",
    "        X.append(combined_features)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "    fit_kmeans = kmeans.fit(X)\n",
    "    create_cluster_dirs(data_dir=data_dir, output_dir=output_dir, labels=fit_kmeans.labels_)\n",
    "    IN_clusters = define_IN_clusters(reference_id=reference_id, threshold=metric_threshold, output_dir=output_dir, metric=metric)\n",
    "\n",
    "    print(IN_clusters)\n",
    "    if len(IN_clusters) == 0 or c != 0:\n",
    "        break\n",
    "\n",
    "    # refine the IN-Cluster\n",
    "    # ....\n",
    "    \n",
    "    # move the refined IN-Cluster (optimal) to another path and reinitiate the clustering process without those fragments\n",
    "    os.makedirs(optimal_dir, exist_ok=True)\n",
    "    \n",
    "    for reference_id, cluster_dirs in IN_clusters.items():\n",
    "        reference_dir = os.path.join(optimal_dir, reference_id)\n",
    "        os.makedirs(reference_dir, exist_ok=True)\n",
    "        \n",
    "        for cluster_dir in cluster_dirs:\n",
    "            img_dir = os.path.join(\"clusters/kmeans/colors_ssim\", cluster_dir)\n",
    "            for filename in os.listdir(img_dir):\n",
    "                shutil.copy(os.path.join(img_dir, filename), os.path.join(reference_dir, filename))\n",
    "                shutil.move(os.path.join(data_dir, filename), os.path.join(optimal_data_dir, filename))\n",
    "            shutil.rmtree(img_dir)\n",
    "        del reference_images_ids[i]\n",
    "        del reference_images[i]\n",
    "    c = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "426f6f7ec7169f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_data(optimal_data_dir, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971992dbb354d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
