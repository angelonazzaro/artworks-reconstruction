{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27eca293e0492052",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "id": "5123b96350f60dd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:33:12.457139Z",
     "start_time": "2024-05-21T12:33:11.513219Z"
    }
   },
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pygments.formatters import img\n",
    "from tqdm import tqdm\n",
    "\n",
    "from preprocessing.edge_extraction import *\n",
    "from feature_extraction import * \n",
    "from preprocessing.fourier_transform import * \n",
    "from preprocessing.image_conversion import * \n",
    "from clustering import *\n",
    "from preprocessing.contrast_enhancement import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "c4cbd2812370b24e",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "To reduce noise in images of whole artworks and fragments, we initially considered using the Fourier transform to process the images in the frequency domain.\n",
    "\n",
    "While converting an image from RGBA to grayscale simplifies processing, it results in the loss of RGB color and alpha channel data, which can be problematic if that information is needed later. Therefore, we chose to split the image into its primary color channels (excluding the alpha channel) and process each channel separately in the frequency domain. After filtering, we planned to reconstruct the filtered image by recombining the processed channels.\n",
    "\n",
    "However, after several trials, we found that processing the channels separately led to significant information loss in one or more channels. Consequently, we decided to use the NLMeansDenoising filter instead.\n",
    "\n",
    "Since our goal is to cluster fragments that belong to the same image, we focus on maintaining \"continuity\" along the fragment borders. Therefore, our process emphasizes the information present along these edges.\n",
    "\n",
    "Steps:\n",
    "1. Extract a working region from the borders of the fragment.\n",
    "2. Filter out the transparent pixels from the working region.\n",
    "3. Denoise the working region.\n",
    "\n",
    "**CONSIDERATION**: Contrast enhancement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e881ed433270655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:47:08.805236Z",
     "start_time": "2024-05-17T20:47:05.317231Z"
    }
   },
   "outputs": [],
   "source": [
    "images = create_dataset(\"./data\", threshold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621d1d1f73e963",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "To extract relevant features from the fragments, we employ two methods:\n",
    "- Color Histograms\n",
    "- Gradient Jacobians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f6711ab6c7ac0",
   "metadata": {},
   "source": [
    "## Color Histograms\n",
    "\n",
    "Color histograms are graphical representations of the distribution of colors in an image. They quantify the number of pixels that have specific color values, effectively capturing the color composition of the image. By analyzing the color histograms of image fragments, we can compare and cluster similar fragments based on their color distributions.\n",
    "\n",
    "**This technique is particularly useful for identifying and matching regions of images that share similar color patterns**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68fc1ff8d4286be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:47:08.816600Z",
     "start_time": "2024-05-17T20:47:08.806178Z"
    }
   },
   "outputs": [],
   "source": [
    "flatten_color_histograms = compute_color_histograms(images)\n",
    "unflatten_color_histograms = compute_color_histograms(images, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda2d0459364a6c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:48:38.216925Z",
     "start_time": "2024-05-17T20:48:37.965198Z"
    }
   },
   "outputs": [],
   "source": [
    "distance_matrix_color_histogram = compute_color_histogram_dist_matrix(unflatten_color_histograms)\n",
    "distance_matrix_color_histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac9ce26-022d-4d08-bca3-cec365f503bc",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "id": "2db0b5ba-22b3-4536-8bb2-b52a116a914e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:33:19.178958Z",
     "start_time": "2024-05-21T12:33:19.163333Z"
    }
   },
   "source": [
    "references = [reference.split(\".\")[1] for reference in os.listdir(\"./references\")]\n",
    "references"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['33', '34', '35', '36', '37', '38', '39', '40']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "befdbdf4-f20b-4f84-a6ee-27663fffa65b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:35:34.300380Z",
     "start_time": "2024-05-21T12:35:23.676865Z"
    }
   },
   "source": [
    "import pickle \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "os.makedirs(\"./optimal_data\", exist_ok=True)\n",
    "\n",
    "while len(references) > 0:\n",
    "    images = create_dataset(\"./data\", threshold=5)\n",
    "    flatten_color_histograms = compute_color_histograms(images)\n",
    "    kmeans = KMeans(n_clusters=len(references), random_state=42)\n",
    "    fit_kmeans = kmeans.fit(flatten_color_histograms)\n",
    "\n",
    "    create_cluster_dirs(data_dir=\"./data\", output_dir=\"clusters/kmeans/colors\", labels=fit_kmeans.labels_)\n",
    "    scores = {}\n",
    "    for reference_id in references:\n",
    "        scores[reference_id] = compute_metrics(reference_id, \"clusters/kmeans/colors\", output_file=f\"results/kmeans_color_n_42_ref_{reference_id}.json\")\n",
    "\n",
    "    threshold = 0.80\n",
    "    opt_clusters = {}\n",
    "    for reference_id, d in scores.items():\n",
    "        max_items = d[\"max_items\"]\n",
    "        for max_item in max_items:\n",
    "            if max_item[1] >= threshold:\n",
    "                if reference_id in opt_clusters:\n",
    "                    opt_clusters[reference_id].append(max_item[0])\n",
    "                else:\n",
    "                    opt_clusters[reference_id] = [max_item[0]]\n",
    "                \n",
    "    # move the optimal clusters to another path and reinitiate the clustering process without those fragments\n",
    "    opt_dir = \"optimal_clusters/kmeans/colors\"\n",
    "    os.makedirs(opt_dir, exist_ok=True)\n",
    "    for reference_id, cluster_dirs in opt_clusters.items():\n",
    "        reference_dir = os.path.join(opt_dir, reference_id)\n",
    "        os.makedirs(reference_dir, exist_ok=True)\n",
    "        for cluster_dir in cluster_dirs:\n",
    "            img_dir = os.path.join(\"clusters/kmeans/colors\", cluster_dir)\n",
    "            for filename in os.listdir(img_dir):\n",
    "                shutil.copy(os.path.join(img_dir, filename), os.path.join(reference_dir, filename))\n",
    "                shutil.move(os.path.join(\"./data\", filename), os.path.join(\"./optimal_data\", filename))\n",
    "            shutil.rmtree(img_dir)\n",
    "        references.remove(reference_id)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dataset: 100%|██████████| 328/328 [00:09<00:00, 33.11it/s]\n",
      "Computing color histograms: 100%|██████████| 328/328 [00:00<00:00, 65629.79it/s]\n",
      "Creating cluster dirs: 100%|██████████| 328/328 [00:00<00:00, 1336.91it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Impossibile trovare il percorso specificato: 'clusters/kmeans/colors\\\\cluster_4'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 37\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cluster_dir \u001B[38;5;129;01min\u001B[39;00m cluster_dirs:\n\u001B[0;32m     36\u001B[0m     img_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclusters/kmeans/colors\u001B[39m\u001B[38;5;124m\"\u001B[39m, cluster_dir)\n\u001B[1;32m---> 37\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m filename \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_dir\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m     38\u001B[0m         shutil\u001B[38;5;241m.\u001B[39mcopy(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(img_dir, filename), os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(reference_dir, filename))\n\u001B[0;32m     39\u001B[0m         shutil\u001B[38;5;241m.\u001B[39mmove(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data\u001B[39m\u001B[38;5;124m\"\u001B[39m, filename), os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./optimal_data\u001B[39m\u001B[38;5;124m\"\u001B[39m, filename))\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] Impossibile trovare il percorso specificato: 'clusters/kmeans/colors\\\\cluster_4'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "784aba06-659c-4e24-9369-09e343906664",
   "metadata": {},
   "source": [
    "## Gradient Jacobians\n",
    "\n",
    "Gradient Jacobians represent the gradients of pixel intensities in an image. They capture the rate of change of pixel values in both the horizontal and vertical directions, highlighting edges and texture details. By computing the Jacobians of image fragments, we can compare and group fragments that exhibit similar edge and texture patterns. Formally, the gradient jacobians we use are of the form:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{bmatrix} G_x & G_{x\\_gray} \\\\ G_y & G_{y\\_gray} \\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $G_x$ and $G_y$ are the aggregated gradient of the RGB channels, while $G_{x\\_gray}$ and $G_{y\\_gray}$ are the gradient of the grayscale image.\n",
    "\n",
    "This method is especially valuable for identifying structural similarities and continuities between different fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278a0609-1f41-4eae-8420-bb684f9d12e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:47:09.689047Z",
     "start_time": "2024-05-17T20:47:09.563755Z"
    }
   },
   "outputs": [],
   "source": [
    "flatten_jacobians = compute_jacobians(images)\n",
    "unflatten_jacobians = compute_jacobians(images, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60522d7-bb8d-4968-8c70-2eda1c4b48b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:49:12.224509Z",
     "start_time": "2024-05-17T20:48:47.297184Z"
    }
   },
   "outputs": [],
   "source": [
    "distance_matrix_jacobians = compute_jacobians_dist_matrix(unflatten_jacobians)\n",
    "distance_matrix_jacobians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb50dcb-230d-499a-9603-48bfbd0b3944",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f2590-032b-4fbc-91a1-66ffe0b2e8fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T20:47:35.475309Z",
     "start_time": "2024-05-17T20:47:35.075774Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "fit_kmeans = kmeans.fit(flatten_jacobians)\n",
    "create_cluster_dirs(data_dir=\"./data\", output_dir=\"clusters/kmeans/jacobians\", labels=fit_kmeans.labels_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
